{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instalar estas librerias \n",
    "!pip install nltk\n",
    "!pip install stanza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Una vez instaladas, bajar los siguientes paquetes de esas librerias (ejecutar unicamente la primera vez)\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stanza.download('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import stanza\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones utiles: ejecutar todas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = stanza.Pipeline(lang='es', processors='tokenize,mwt,pos,lemma')\n",
    "#Documentacion stanza: https://stanfordnlp.github.io/stanza/lemma.html\n",
    "#Toma como imput un string crudo porq lematiza por contexto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir pandas dataframe\n",
    "df = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de mensajes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import procesar_articulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procesado = procesar_articulos((df.reset_index())['columna_de_contenido'], nlp, language = 'spanish')\n",
    "#Esta funcion toma como imput un pd.series de strings. \n",
    "#poner la columna con las encuestas nada mas\n",
    "#IMPORTANTE: no borrar el reset_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir solo una vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_helper import plot_top_words, get_keys, keys_to_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(max_df = 0.8, min_df = 10) \n",
    "#si el vocabulario te queda chico, podes bajar el parametro \"min_df\". Lo que hace es tomar unicamente las palabras \n",
    "#q aparecen en mas de n documentos. En este caso, 10. No lo bajes tanto para evitar que aparezca mucha basura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_df = count_vectorizer.fit_transform(df_procesado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ejecutas el LDA, lo de arriba no hace falta volver a definirlo para cambiar la cantidad de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 4    #cantidad de clusters. cambiar desde aca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components=n_topics,\n",
    "                                          random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_topic_matrix = lda_model.fit_transform(vectorized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aca te aparecen las palabras mas importantes por cluster\n",
    "\n",
    "vocab = count_vectorizer.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(lda_model.components_):\n",
    "    vocab_comp = zip(vocab, comp)\n",
    "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:20] #El 20 es la cantidad de palabras q aparecen\n",
    "    print(\"Topic \"+str(i+1)+\": \")\n",
    "    for t in sorted_words:\n",
    "        print(t[0],end=\" \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_keys = get_keys(lda_topic_matrix)\n",
    "lda_categories, lda_counts = keys_to_counts(lda_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_words(lda_model, count_vectorizer.get_feature_names(), 20, 'Top words LDA clustering', cols = int(n_topics/2))\n",
    "#El 20 es la cantidad de palabras que queres que aparezcan por cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Topic '+str(i+1)+ '\\n'.format(i) for i in lda_categories]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.bar(lda_categories, lda_counts);\n",
    "ax.set_xticks(lda_categories);\n",
    "ax.set_xticklabels(labels);\n",
    "ax.set_ylabel('Cantidad de reviews');\n",
    "ax.set_title('Cantidad de reviews por cluster LDA');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
